{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32df29ca-6cb0-43d8-8608-39ef01e0a84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ijson\n",
      "  Downloading ijson-3.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (21 kB)\n",
      "Downloading ijson-3.3.0-cp311-cp311-macosx_11_0_arm64.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ijson\n",
      "Successfully installed ijson-3.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ijson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6236ecda-366d-4edb-967c-dbf7cc2893e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min, sys: 3.78 s, total: 3min 4s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import ijson\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "#file year \n",
    "year = 2025\n",
    "file_path = f\"../data/raw/raw_subset/new_amplitude_export_{year}.json\"\n",
    "\n",
    "#non-empty columns\n",
    "columns_keep = [\n",
    "    \"$insert_id\",\n",
    "    \"amplitude_id\",\n",
    "    \"app\",\n",
    "    \"city\",\n",
    "    \"client_event_time\",\n",
    "    \"client_upload_time\",\n",
    "    \"country\",\n",
    "    \"data\",\n",
    "    \"data_type\",\n",
    "    \"device_family\",\n",
    "    \"device_id\",\n",
    "    \"device_type\",\n",
    "    \"dma\",\n",
    "    \"event_id\",\n",
    "    \"event_properties\",\n",
    "    \"event_time\",\n",
    "    \"event_type\",\n",
    "    \"language\",\n",
    "    \"library\",\n",
    "    \"os_name\",\n",
    "    \"os_version\",\n",
    "    \"platform\",\n",
    "    \"processed_time\",\n",
    "    \"region\",\n",
    "    \"server_received_time\",\n",
    "    \"server_upload_time\",\n",
    "    \"session_id\",\n",
    "    \"user_id\",\n",
    "    \"user_properties\",\n",
    "    \"uuid\",\n",
    "]\n",
    "path = Path(f\"{year}_csv\")\n",
    "if not path.exists():\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "#use ijson to read the json files efficiently in memory\n",
    "with open(file_path, \"r\") as f:\n",
    "    objects = ijson.items(f, \"item\") #creates a generator object\n",
    "    \n",
    "    batch_size = 100000 #can be updated, currently saves per batches of 100,000\n",
    "    chunk = []\n",
    "    count = 0 #used to index batch file\n",
    "    for obj in objects:\n",
    "        chunk.append(obj)\n",
    "        if len(chunk) >= batch_size:\n",
    "            df = pd.DataFrame(chunk)\n",
    "            output_csv = f\"{year}_csv/{file_path.split('.')[0]}_chunk_{count*batch_size}_{(count+1)*batch_size}.csv\"\n",
    "            df = df[columns_keep] #remove empty columns\n",
    "            df.to_csv(output_csv, index=False)\n",
    "            count += 1\n",
    "            chunk = []\n",
    "\n",
    "    if chunk: #process remaining data if any\n",
    "        output_csv = f\"{year}_csv/{file_path.split('.')[0]}_chunk_{count*batch_size}_{(count+1)*batch_size}.csv\"\n",
    "        df = pd.DataFrame(chunk)\n",
    "        df = df[columns_keep]\n",
    "        df.to_csv(output_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04213331-46fc-470f-a8a5-3c27569c3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import ijson\n",
    "# import pandas as pd\n",
    "# from pathlib import Path\n",
    "\n",
    "# #file chunk \n",
    "# part = 1\n",
    "# file_path = f\"new_export/amplitude_export_chunk_{part}_anonymized.json\"\n",
    "\n",
    "# #non-empty columns\n",
    "# columns_keep = [\n",
    "#     \"$insert_id\",\n",
    "#     \"amplitude_id\",\n",
    "#     \"app\",\n",
    "#     \"city\",\n",
    "#     \"client_event_time\",\n",
    "#     \"client_upload_time\",\n",
    "#     \"country\",\n",
    "#     \"data\",\n",
    "#     \"data_type\",\n",
    "#     \"device_family\",\n",
    "#     \"device_id\",\n",
    "#     \"device_type\",\n",
    "#     \"dma\",\n",
    "#     \"event_id\",\n",
    "#     \"event_properties\",\n",
    "#     \"event_time\",\n",
    "#     \"event_type\",\n",
    "#     \"language\",\n",
    "#     \"library\",\n",
    "#     \"os_name\",\n",
    "#     \"os_version\",\n",
    "#     \"platform\",\n",
    "#     \"processed_time\",\n",
    "#     \"region\",\n",
    "#     \"server_received_time\",\n",
    "#     \"server_upload_time\",\n",
    "#     \"session_id\",\n",
    "#     \"user_id\",\n",
    "#     \"user_properties\",\n",
    "#     \"uuid\",\n",
    "# ]\n",
    "\n",
    "# path = Path(f\"{part}_csv\")\n",
    "# if not path.exists():\n",
    "#     path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# #use ijson to read the json files efficiently in memory\n",
    "# with open(file_path, \"r\") as f:\n",
    "#     objects = ijson.items(f, \"item\") #creates a generator object\n",
    "    \n",
    "#     batch_size = 100000 #can be updated, currently saves per batches of 100,000\n",
    "#     chunk = []\n",
    "#     count = 0 #used to index batch file\n",
    "#     for obj in objects:\n",
    "#         chunk.append(obj)\n",
    "#         if len(chunk) >= batch_size:\n",
    "#             df = pd.DataFrame(chunk)\n",
    "#             output_csv = f\"{part}_csv/{file_path.split('/')[1].split('.')[0]}_subchunk_{count*batch_size}_{(count+1)*batch_size}.csv\"\n",
    "#             df = df[columns_keep] #remove empty columns\n",
    "#             df.to_csv(output_csv, index=False)\n",
    "#             count += 1\n",
    "#             chunk = []\n",
    "\n",
    "#     if chunk: #process remaining data if any\n",
    "#         output_csv = f\"{part}_csv/{file_path.split('/')[1].split('.')[0]}_subchunk_{count*batch_size}_{(count+1)*batch_size}.csv\"\n",
    "#         df = pd.DataFrame(chunk)\n",
    "#         print(df.shape)\n",
    "#         df = df[columns_keep]\n",
    "#         print(df.shape)\n",
    "#         df.to_csv(output_csv, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
